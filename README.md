# "AVOKE: an open-source web-based experimentation toolbox for evoking audiovisual responses"

**Contributors:** Jackson Shi, Shreshth Saxena, Lauren Fink

## Demo
Example trials for each plugin and extension. 

<a href="https://beatlab-mcmaster.github.io/AVOKE/">View Demo </a>

## About the project
As web-based experiments become increasingly popular, the need for accessible, efficient research methods is greater than ever. However, current open-source frameworks sometimes lack detailed documentation, leaving many novice researchers struggling to create their experiments without significant time investments in learning the required technical skills. To meet this demand and further the capabilities of web-based experiments, we propose AVOKE—a diverse set of experimentation plugins and extensions built on top of jsPsych, an open-source JavaScript library for web-based behavioural experiments. AVOKE includes the code and documentation needed for novice researchers to easily integrate a variety of audiovisual stimuli in their experiments. Currently, AVOKE supports temporally-precise presentation of audiovisual stimuli (e.g., external media sources like YouTube, moving objects, etc.), as well as the collection of behavioural responses, like keypresses and video capture (e.g., for recording face videos or participants). All features have been developed according to jsPsych standards and validated through numerous tests developed in Jest—an established open-source JavaScript testing framework. Here, we elaborate on the implementation, data output structure, usage examples, and limitations of the different plugins and extensions comprising AVOKE. We also discuss potential future additions to enhance usability and diversify the feature set of AVOKE. Upon finalization, we hope to integrate AVOKE into the official jsPsych library. Overall, AVOKE fills a gap in existing web-based methods by enabling easy simultaneous presentation and recording of visuals and sound. As an open-source package, we hope for others to contribute to AVOKE as we continue to push the boundaries of web-based audiovisual experiments.

## Documentation
The `docs` folder for each plugin or extension contains its own README file documenting usage. These docs are also linked below for easy reference: 

<a href="https://github.com/beatlab-mcmaster/AVOKE/blob/main/extension-video-capture/docs/jspsych-video-capture.md">extension-video-capture </a>

<a href="https://github.com/beatlab-mcmaster/AVOKE/blob/main/plugin-audio-visual-button-response/docs/jspsych-audio-visual-response.md">plugin-audiovisual-response </a>

<a href="https://github.com/beatlab-mcmaster/AVOKE/blob/main/plugin-fix-point-calibration/docs/jspsych-fix-point-calibration.md">plugin-fix-point-calibration</a>

<a href="https://github.com/beatlab-mcmaster/AVOKE/blob/main/plugin-smooth-pursuit-calibration/docs/jspsych-smooth-pursuit-calibration.md">plugin-smooth-pursuit-calibration </a>

<a href="https://github.com/beatlab-mcmaster/AVOKE/blob/main/plugin-video-capture-setup/docs/jspsych-video-capture-setup.md">plugin-video-capture-setup </a>

<a href="https://github.com/beatlab-mcmaster/AVOKE/blob/main/plugin-youtube-button-response/docs/jspsych-youtube-button-response.md">plugin-youtube-button-response </a>

## Citation
If using anything from this toolbox, please cite: 

TODO get zenodo DOI for this repo? 